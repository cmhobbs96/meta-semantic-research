{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW8Xcv9jcgfj"
      },
      "source": [
        "# 2. Baseline Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cmhobbs96/meta-semantic-research.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpBzlXm2ehWY",
        "outputId": "3517f3ae-a2ed-4ee4-ba23-bc78147746e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'meta-semantic-research' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "!pip install --upgrade nltk gensim google-colab tensorflow torch torchvision numba pandas --no-cache-dir\n",
        "!pip install OpenNMT-py"
      ],
      "metadata": {
        "id": "ER2imf-6StlH",
        "outputId": "4a2193b6-31af-4b11-ff28-5cbbf1a3da0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nlkt 3.0.0 requires pandas==2.2.3, but you have pandas 2.2.2 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (0.61.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: google-auth==2.38.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.38.0)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.17.1)\n",
            "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.7 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.7)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n",
            "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0->google-colab) (4.9)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.0.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.7.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2025.1.31)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba) (0.44.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->notebook==6.5.7->google-colab) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.7->google-colab) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.7->google-colab) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.38.0->google-colab) (0.6.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.7->google-colab) (21.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.23.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.3.1)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m259.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m299.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m293.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m277.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m345.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m309.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m276.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m276.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m203.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m282.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m286.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m280.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m282.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.2\n",
            "    Uninstalling torch-2.2.2:\n",
            "      Successfully uninstalled torch-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opennmt-py 3.5.1 requires torch<2.3,>=2.1, but you have torch 2.6.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 triton-3.2.0\n",
            "Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Collecting torch<2.3,>=2.1 (from OpenNMT-py)\n",
            "  Using cached torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.7)\n",
            "Requirement already satisfied: ctranslate2<5,>=4 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.19.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.1.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.0.2)\n",
            "Requirement already satisfied: pyonmttok<2,>=1.37 in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.37.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (6.0.2)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.5.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.12.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (2.1.0)\n",
            "Requirement already satisfied: fasttext-wheel in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (0.9.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (3.8.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from OpenNMT-py) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (5.29.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->OpenNMT-py) (12.4.127)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext-wheel->OpenNMT-py) (2.13.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->OpenNMT-py) (1.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->OpenNMT-py) (5.3.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (2.10.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->OpenNMT-py) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3,>=2.1->OpenNMT-py) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (7.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3,>=2.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (0.1.2)\n",
            "Using cached torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast\n",
        "from torch.cuda.amp import GradScaler\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
        "import OpenNMT_py\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from difflib import unified_diff\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  scaler = GradScaler()\n",
        "  os.system(\"nvidia-smi\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  scaler = None"
      ],
      "metadata": {
        "id": "2eE2JOkwzVtS",
        "outputId": "a017a22a-8cbe-4754-9848-ebb2903cbafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'OpenNMT_py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-657c92793c86>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mOpenNMT_py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'OpenNMT_py'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuning Hyperparameters**"
      ],
      "metadata": {
        "id": "fI6mnzZKrc3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Hyperparameters\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_LENGTH = 128\n",
        "ACCUMULATION_STEPS = 2\n",
        "\n",
        "all_results = []"
      ],
      "metadata": {
        "id": "7N0hnoGfriGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to Data**"
      ],
      "metadata": {
        "id": "E_f5vJ4nsHCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for datasets\n",
        "train_path = \"/content/drive/My Drive/Academia/MS in AI/ECE 57000/Research/data/train.tsv\"\n",
        "test_path = \"/content/drive/My Drive/Academia/MS in AI/ECE 57000/Research/data/test.tsv\"\n",
        "gen_path = \"/content/drive/My Drive/Academia/MS in AI/ECE 57000/Research/data/gen.tsv\""
      ],
      "metadata": {
        "id": "_cuLpliU1D7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspect Data**"
      ],
      "metadata": {
        "id": "xsTOgFEIsNgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check dataset format\n",
        "def inspect_dataset(file_path, file_name):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "        print(f\"\\n Inspecting {file_name}:\")\n",
        "        print(data.head(5))  # Print first 5 rows\n",
        "        print(f\"Columns: {data.columns}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "# Inspect each dataset\n",
        "inspect_dataset(train_path, \"train.tsv\")\n",
        "inspect_dataset(test_path, \"test.tsv\")\n",
        "inspect_dataset(gen_path, \"gen.tsv\")"
      ],
      "metadata": {
        "id": "00oiS7CxRDlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset**"
      ],
      "metadata": {
        "id": "fYmJcbp6gMfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset class for COGS\n",
        "class COGSDataset(Dataset):\n",
        "  def __init__(self, file_path, tokenizer):\n",
        "    self.data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"input\", \"output\", \"split\"]).iloc[:, :2]\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_text = self.data.iloc[index][\"input\"]\n",
        "    output_text = self.data.iloc[index][\"output\"]\n",
        "\n",
        "    inputs = self.tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "    targets = self.tokenizer(output_text, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"labels\": targets[\"input_ids\"].squeeze()\n",
        "    }"
      ],
      "metadata": {
        "id": "2wMJziiKfMOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, epochs=NUM_EPOCHS):\n",
        "  model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  accumulation_steps = ACCUMULATION_STEPS\n",
        "  scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "  print(\"Training Model on:\", next(model.parameters()).device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      with autocast(\"cuda\"):\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss / accumulation_steps\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "\n",
        "      if (i + 1) % accumulation_steps == 0:\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "ZlLUt9xMzf9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug Model\n",
        "def debug_model(model, test_loader, dataset_name):\n",
        "  model.eval()\n",
        "  exact_match = 0\n",
        "  total = 0\n",
        "  num_samples_to_check = 10\n",
        "  checked = 0\n",
        "  predictions_list = []\n",
        "  references_list = []\n",
        "\n",
        "  print(\"Debugging Model on:\", next(model.parameters()).device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      input_ids = batch[\"input_ids\"].to(device)\n",
        "      attention_mask = batch[\"attention_mask\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device)\n",
        "\n",
        "      print(f\"input_ids.shape: {input_ids.shape}\")\n",
        "      print(\"Sample input_ids[0]:\", input_ids[0])\n",
        "      print(\"Decoded input[0]:\", tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
        "\n",
        "      # Generate predictions\n",
        "      outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=64,\n",
        "        do_sample=True,\n",
        "        temperature=1.5,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "      predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "      references = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "      for i in range(len(predictions)):\n",
        "        print(f\"--- Sample {checked + 1} ---\")\n",
        "\n",
        "        print(f\"[Input Text]        : {tokenizer.decode(input_ids[i], skip_special_tokens=True)}\")\n",
        "        print(f\"[Input Tokens]      : {input_ids[i].tolist()}\")\n",
        "        print(f\"[Label Tokens]      : {labels[i].tolist()}\")\n",
        "        print(f\"[Generated Tokens]  : {outputs[i].tolist()}\")\n",
        "        print(f\"[Reference Text]    : {references[i]}\")\n",
        "        print(f\"[Predictions]       : {predictions[i]}\")\n",
        "\n",
        "        # Quick check for empty predictions\n",
        "        if len(predictions[i].strip()) == 0:\n",
        "            print(\"EMPTY PREDICTION\")\n",
        "\n",
        "        # Check if it's an exact match\n",
        "        if predictions[i].strip() == references[i].strip():\n",
        "            print(\"Exact Match\")\n",
        "        else:\n",
        "            print(\"Mismatch\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        checked += 1\n",
        "        if checked >= num_samples_to_check:\n",
        "            break\n",
        "      if checked >= num_samples_to_check:\n",
        "        break"
      ],
      "metadata": {
        "id": "xqR904ggbhuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "def evaluate_model(model, test_loader, dataset_name):\n",
        "  start_time = time.time()\n",
        "  model.eval()\n",
        "  exact_match = 0\n",
        "  total = 0\n",
        "  predictions_list = []\n",
        "  references_list = []\n",
        "\n",
        "  sample_precisions = []\n",
        "  sample_recalls = []\n",
        "  sample_f1s = []\n",
        "  sample_bleus = []\n",
        "\n",
        "  smoothie = SmoothingFunction().method4\n",
        "\n",
        "  print(\"Evaluating Model on:\", next(model.parameters()).device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_loader):\n",
        "      input_ids = batch[\"input_ids\"].to(device)\n",
        "      attention_mask = batch[\"attention_mask\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device)\n",
        "\n",
        "      # Generate predictions\n",
        "      outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "      )\n",
        "\n",
        "      decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "      references = [\n",
        "          tokenizer.decode(label[label != -100], skip_special_tokens=True)\n",
        "          for label in labels\n",
        "      ]\n",
        "      predictions = [\n",
        "          tokenizer.decode(output, skip_special_tokens=True)\n",
        "          for output in outputs\n",
        "      ]\n",
        "\n",
        "      # Append to lists\n",
        "      predictions_list.extend(predictions)\n",
        "      references_list.extend(references)\n",
        "\n",
        "      # Calculate exact match\n",
        "      exact_match += sum([1 for pred, ref in zip(predictions, references) if pred.strip() == ref.strip()])\n",
        "      total += len(predictions)\n",
        "\n",
        "\n",
        "      # Token-level precision, recall, f1 per sample\n",
        "      for pred, ref in zip(predictions, references):\n",
        "        pred_tokens = pred.split()\n",
        "        ref_tokens = ref.split()\n",
        "\n",
        "        # BLEU Score\n",
        "        if len(pred_tokens) > 0 and len(ref_tokens) > 0:\n",
        "          bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "          sample_bleus.append(bleu)\n",
        "\n",
        "        # Token-level metrics\n",
        "        min_len = min(len(pred_tokens), len(ref_tokens))\n",
        "        if min_len == 0:\n",
        "            continue  # skip empty predictions or references\n",
        "        pred_slice = pred_tokens[:min_len]\n",
        "        ref_slice = ref_tokens[:min_len]\n",
        "\n",
        "        sample_precisions.append(precision_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "        sample_recalls.append(recall_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "        sample_f1s.append(f1_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "\n",
        "      if batch_idx % 10 == 0:\n",
        "        print(f\"Batch {batch_idx}: Processed {total} examples...\")\n",
        "\n",
        "  # Final metrics\n",
        "  exact_match_score = 100 * exact_match / total\n",
        "  precision = 100 * np.mean(sample_precisions)\n",
        "  recall = 100 * np.mean(sample_recalls)\n",
        "  f1 = 100 * np.mean(sample_f1s)\n",
        "  bleu = 100 * np.mean(sample_bleus)\n",
        "  elapsed_time = time.time() - start_time\n",
        "\n",
        "  # Print 5 sample predictions for debugging\n",
        "  print(f\"\\n** {dataset_name} Sample Predictions vs. References:**\")\n",
        "  for i in range(min(5, len(predictions_list))):\n",
        "    print(f\"{dataset_name} Prediction {i+1}: {predictions_list[i]}\")\n",
        "    print(f\"{dataset_name} Reference {i+1}: {references_list[i]}\\n\")\n",
        "\n",
        "  print(f\"{dataset_name} Exact Match Score: {exact_match_score:.4f}%\")\n",
        "  print(f\"{dataset_name} Precision: {precision:.4f}%\")\n",
        "  print(f\"{dataset_name} Recall: {recall:.4f}%\")\n",
        "  print(f\"{dataset_name} F1 Score: {f1:.4f}%\")\n",
        "  print(f\"{dataset_name} BLEU Score: {bleu:.4f}%\")\n",
        "  print(f\"{dataset_name} Elapsed Time: {elapsed_time} seconds\")\n",
        "\n",
        "  return {\n",
        "      \"exact_match\": exact_match_score,\n",
        "      \"precision\": precision,\n",
        "      \"recall\": recall,\n",
        "      \"f1\": f1,\n",
        "      \"bleu\": bleu,\n",
        "      \"elapsed_time\": elapsed_time\n",
        "  }"
      ],
      "metadata": {
        "id": "rSWIuTjSRr9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T5 Model**"
      ],
      "metadata": {
        "id": "ad-b7tFW2Gq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"T5\"\n",
        "MODEL_PATH = \"google-t5/t5-small\"\n",
        "DEBUG = True\n",
        "\n",
        "print(f\"\\n---- Evaluating {MODEL_NAME} ----\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(device)\n",
        "\n",
        "# Create dataset with current tokenizer\n",
        "train_dataset = COGSDataset(train_path, tokenizer)\n",
        "test_dataset = COGSDataset(test_path, tokenizer)\n",
        "gen_dataset = COGSDataset(gen_path, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train the Model\n",
        "train_model(model, train_loader, optimizer)\n",
        "\n",
        "# Check trained model\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.grad is not None}\")\n",
        "\n",
        "# Save model\n",
        "output_dir = f\"models/{MODEL_NAME}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Training complete. Model saved to: {output_dir}\")\n",
        "\n",
        "# Evaluate the Model\n",
        "if DEBUG == True:\n",
        "  debug_results = debug_model(model, test_loader, \"Test Set\")\n",
        "else:\n",
        "  test_results = evaluate_model(model, test_loader, \"Test Set\")\n",
        "  test_results.update({\"model\": MODEL_NAME, \"set\": \"Test\"})\n",
        "\n",
        "  gen_results = evaluate_model(model, gen_loader, \"Generalization Set\")\n",
        "  gen_results.update({\"model\": MODEL_NAME, \"set\": \"Generalization\"})\n",
        "\n",
        "  all_results.extend([test_results, gen_results])"
      ],
      "metadata": {
        "id": "VMM313pA2Ith"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BART Model**"
      ],
      "metadata": {
        "id": "nNfUBC-c2qgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"BART\"\n",
        "MODEL_PATH = \"facebook/bart-base\"\n",
        "DEBUG = True\n",
        "\n",
        "print(f\"\\n---- Evaluating {MODEL_NAME} ----\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(device)\n",
        "\n",
        "# Create dataset with current tokenizer\n",
        "train_dataset = COGSDataset(train_path, tokenizer)\n",
        "test_dataset = COGSDataset(test_path, tokenizer)\n",
        "gen_dataset = COGSDataset(gen_path, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train the Model\n",
        "train_model(model, train_loader, optimizer)\n",
        "\n",
        "# Check trained model\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.grad is not None}\")\n",
        "\n",
        "# Save model\n",
        "output_dir = f\"models/{MODEL_NAME}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Training complete. Model saved to: {output_dir}\")\n",
        "\n",
        "# Evaluate the Model\n",
        "if DEBUG == True:\n",
        "  debug_results = debug_model(model, test_loader, \"Test Set\")\n",
        "else:\n",
        "  test_results = evaluate_model(model, test_loader, \"Test Set\")\n",
        "  test_results.update({\"model\": MODEL_NAME, \"set\": \"Test\"})\n",
        "\n",
        "  gen_results = evaluate_model(model, gen_loader, \"Generalization Set\")\n",
        "  gen_results.update({\"model\": MODEL_NAME, \"set\": \"Generalization\"})\n",
        "\n",
        "  all_results.extend([test_results, gen_results])"
      ],
      "metadata": {
        "id": "QxluLl1v2qAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenNMT Debug and Evaluating**"
      ],
      "metadata": {
        "id": "umB_Fk_JGZXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_opennmt(model_path, src_file, ref_file, num_samples_to_check=10):\n",
        "    print(f\"\\n---- Debugging {MODEL_NAME} ----\")\n",
        "\n",
        "    # Create a temporary debug file\n",
        "    debug_output_file = os.path.join(output_dir, \"debug_predictions.txt\")\n",
        "\n",
        "    # Run OpenNMT Translation on the test set\n",
        "    translate_command = [\n",
        "        \"python\", \"-m\", \"onmt.bin.translate\",\n",
        "        \"-model\", model_path,\n",
        "        \"-src\", src_file,\n",
        "        \"-output\", debug_output_file,\n",
        "        \"-gpu\", \"0\" if torch.cuda.is_available() else \"-1\",\n",
        "        \"-batch_size\", \"1\",\n",
        "        \"-beam_size\", \"5\"\n",
        "    ]\n",
        "    subprocess.run(translate_command)\n",
        "\n",
        "    # Load original inputs & references\n",
        "    with open(src_file, \"r\") as src_f, open(ref_file, \"r\") as ref_f, open(debug_output_file, \"r\") as pred_f:\n",
        "        inputs = src_f.readlines()\n",
        "        references = ref_f.readlines()\n",
        "        predictions = pred_f.readlines()\n",
        "\n",
        "    # Ensure length matches\n",
        "    num_samples = min(len(inputs), len(references), len(predictions), num_samples_to_check)\n",
        "\n",
        "    exact_match = 0\n",
        "    print(\"\\n---- Debugging Output ----\")\n",
        "    for i in range(num_samples):\n",
        "        input_text = inputs[i].strip()\n",
        "        reference_text = references[i].strip()\n",
        "        prediction_text = predictions[i].strip()\n",
        "\n",
        "        print(f\"--- Sample {i + 1} ---\")\n",
        "        print(f\"[Input Text]        : {input_text}\")\n",
        "        print(f\"[Reference Text]    : {reference_text}\")\n",
        "        print(f\"[Predictions]       : {prediction_text}\")\n",
        "\n",
        "        # Quick check for empty predictions\n",
        "        if len(prediction_text.strip()) == 0:\n",
        "            print(\"EMPTY PREDICTION\")\n",
        "\n",
        "        # Check if it's an exact match\n",
        "        if prediction_text.strip() == reference_text.strip():\n",
        "            print(\"Exact Match\")\n",
        "            exact_match += 1\n",
        "        else:\n",
        "            print(\"Mismatch\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "    # Print accuracy\n",
        "    match_rate = (exact_match / num_samples) * 100\n",
        "    print(f\"Debugging Complete! Exact Match Rate: {match_rate:.2f}%\\n\")\n",
        "\n",
        "    return {\"model\": MODEL_NAME, \"set\": \"Debug\", \"exact_match_rate\": match_rate}"
      ],
      "metadata": {
        "id": "rmsORIgiMe0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_opennmt(model_path, src_file, ref_file, dataset_name):\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"\\n---- Evaluating {MODEL_NAME} on {dataset_name} ----\")\n",
        "\n",
        "    # Create temporary output file for predictions\n",
        "    output_file = os.path.join(output_dir, f\"{dataset_name}_predictions.txt\")\n",
        "\n",
        "    # Run OpenNMT translation\n",
        "    translate_command = [\n",
        "        \"python\", \"-m\", \"onmt.bin.translate\",\n",
        "        \"-model\", model_path,\n",
        "        \"-src\", src_file,\n",
        "        \"-output\", output_file,\n",
        "        \"-gpu\", \"0\" if torch.cuda.is_available() else \"-1\",\n",
        "        \"-batch_size\", \"32\",\n",
        "        \"-beam_size\", \"5\"\n",
        "    ]\n",
        "    subprocess.run(translate_command)\n",
        "\n",
        "    # Load reference and prediction files\n",
        "    with open(ref_file, \"r\") as ref_f, open(output_file, \"r\") as pred_f:\n",
        "        references = [line.strip() for line in ref_f.readlines()]\n",
        "        predictions = [line.strip() for line in pred_f.readlines()]\n",
        "\n",
        "    # Ensure we only evaluate the number of samples available\n",
        "    total = min(len(references), len(predictions))\n",
        "\n",
        "    exact_match = 0\n",
        "    predictions_list = []\n",
        "    references_list = []\n",
        "    sample_precisions = []\n",
        "    sample_recalls = []\n",
        "    sample_f1s = []\n",
        "    sample_bleus = []\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    for i in range(total):\n",
        "        ref = references[i]\n",
        "        pred = predictions[i]\n",
        "\n",
        "        predictions_list.append(pred)\n",
        "        references_list.append(ref)\n",
        "\n",
        "        # Check exact match\n",
        "        if pred == ref:\n",
        "            exact_match += 1\n",
        "\n",
        "        # Token-level precision, recall, f1 per sample\n",
        "        pred_tokens = pred.split()\n",
        "        ref_tokens = ref.split()\n",
        "\n",
        "        # BLEU Score\n",
        "        if len(pred_tokens) > 0 and len(ref_tokens) > 0:\n",
        "            bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "            sample_bleus.append(bleu)\n",
        "\n",
        "        # Token-level metrics\n",
        "        min_len = min(len(pred_tokens), len(ref_tokens))\n",
        "        if min_len == 0:\n",
        "            continue  # Skip empty predictions or references\n",
        "        pred_slice = pred_tokens[:min_len]\n",
        "        ref_slice = ref_tokens[:min_len]\n",
        "\n",
        "        sample_precisions.append(precision_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "        sample_recalls.append(recall_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "        sample_f1s.append(f1_score(ref_slice, pred_slice, average='macro', zero_division=0))\n",
        "\n",
        "    # Compute final metrics\n",
        "    exact_match_score = 100 * exact_match / total\n",
        "    precision = 100 * np.mean(sample_precisions)\n",
        "    recall = 100 * np.mean(sample_recalls)\n",
        "    f1 = 100 * np.mean(sample_f1s)\n",
        "    bleu = 100 * np.mean(sample_bleus)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Print 5 sample predictions\n",
        "    print(f\"\\n** {dataset_name} Sample Predictions vs. References:**\")\n",
        "    for i in range(min(5, total)):\n",
        "        print(f\"{dataset_name} Prediction {i+1}: {predictions_list[i]}\")\n",
        "        print(f\"{dataset_name} Reference {i+1}: {references_list[i]}\\n\")\n",
        "\n",
        "    print(f\"{dataset_name} Exact Match Score: {exact_match_score:.4f}%\")\n",
        "    print(f\"{dataset_name} Precision: {precision:.4f}%\")\n",
        "    print(f\"{dataset_name} Recall: {recall:.4f}%\")\n",
        "    print(f\"{dataset_name} F1 Score: {f1:.4f}%\")\n",
        "    print(f\"{dataset_name} BLEU Score: {bleu:.4f}%\")\n",
        "    print(f\"{dataset_name} Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    return {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"set\": dataset_name,\n",
        "        \"exact_match\": exact_match_score,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"bleu\": bleu,\n",
        "        \"elapsed_time\": elapsed_time\n",
        "    }"
      ],
      "metadata": {
        "id": "yW_g9d6_M_QE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPENNMT Model**"
      ],
      "metadata": {
        "id": "YFF108BTKnsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output directory for OpenNMT\n",
        "MODEL_NAME = \"OPENNMT\"\n",
        "output_dir = \"opennmt_data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to preprocess COGS dataset for OpenNMT\n",
        "def preprocess_cogs(file_path, prefix):\n",
        "    data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"input\", \"output\"])\n",
        "\n",
        "    # Save source (input) and target (output) files\n",
        "    input_file = os.path.join(output_dir, f\"{prefix}.src\")\n",
        "    output_file = os.path.join(output_dir, f\"{prefix}.tgt\")\n",
        "\n",
        "    data[\"input\"].to_csv(input_file, index=False, header=False)\n",
        "    data[\"output\"].to_csv(output_file, index=False, header=False)\n",
        "\n",
        "    print(f\"Processed {file_path}: Saved {input_file} and {output_file}\")\n",
        "\n",
        "# Run preprocessing on datasets\n",
        "preprocess_cogs(train_path, \"train\")\n",
        "preprocess_cogs(test_path, \"test\")\n",
        "preprocess_cogs(gen_path, \"gen\")\n",
        "\n",
        "print(\"Preprocessing complete! Ready for OpenNMT training.\")\n",
        "\n",
        "train_command = [\n",
        "    \"python\", \"-m\", \"onmt.bin.train\",\n",
        "    \"-data\", \"opennmt_data/cogs_preprocessed\",\n",
        "    \"-save_model\", \"models/cogs_baseline\",\n",
        "    \"-layers\", \"2\",\n",
        "    \"-rnn_size\", \"512\",\n",
        "    \"-word_vec_size\", \"512\",\n",
        "    \"-train_steps\", \"50000\",\n",
        "    \"-batch_size\", \"32\",\n",
        "    \"-valid_steps\", \"1000\"\n",
        "]\n",
        "\n",
        "# Run OpenNMT Training\n",
        "subprocess.run(train_command)\n",
        "\n",
        "# Save Model\n",
        "output_dir = f\"models/{MODEL_NAME}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\n---- Saving Model ----\")\n",
        "\n",
        "# Move trained model to the output directory\n",
        "trained_model_path = \"models/cogs_baseline_step_50000.pt\"\n",
        "new_model_path = os.path.join(output_dir, \"cogs_model.pt\")\n",
        "os.rename(trained_model_path, new_model_path)\n",
        "\n",
        "print(f\"Training complete. Model saved to: {new_model_path}\")\n",
        "\n",
        "# Define test and generalization files\n",
        "test_file = \"opennmt_data/test.src\"\n",
        "gen_file = \"opennmt_data/gen.src\"\n",
        "test_output = os.path.join(output_dir, \"test_predictions.txt\")\n",
        "gen_output = os.path.join(output_dir, \"gen_predictions.txt\")\n",
        "\n",
        "if DEBUG:\n",
        "    print(\"Debug mode: Checking model outputs.\")\n",
        "    debug_opennmt(new_model_path, test_file, test_output)\n",
        "else:\n",
        "    print(\"Evaluating model on test and generalization sets...\")\n",
        "    evaluate_opennmt(new_model_path, test_file, test_output)\n",
        "    evaluate_opennmt(new_model_path, gen_file, gen_output)\n",
        "\n",
        "print(\"Evaluation complete!\")\n"
      ],
      "metadata": {
        "id": "A0KCazQbKtqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT Model**"
      ],
      "metadata": {
        "id": "UsnM-bOP251H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"GPT\"\n",
        "MODEL_PATH = \"microsoft/phi-2\"\n",
        "DEBUG = True\n",
        "\n",
        "print(f\"\\n---- Evaluating {MODEL_NAME} ----\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(device)\n",
        "\n",
        "# Create dataset with current tokenizer\n",
        "train_dataset = COGSDataset(train_path, tokenizer)\n",
        "test_dataset = COGSDataset(test_path, tokenizer)\n",
        "gen_dataset = COGSDataset(gen_path, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train the Model\n",
        "train_model(model, train_loader, optimizer)\n",
        "\n",
        "# Check trained model\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.grad is not None}\")\n",
        "\n",
        "# Save model\n",
        "output_dir = f\"models/{MODEL_NAME}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Training complete. Model saved to: {output_dir}\")\n",
        "\n",
        "# Evaluate the Model\n",
        "if DEBUG == True:\n",
        "  debug_results = debug_model(model, test_loader, \"Test Set\")\n",
        "else:\n",
        "  test_results = evaluate_model(model, test_loader, \"Test Set\")\n",
        "  test_results.update({\"model\": MODEL_NAME, \"set\": \"Test\"})\n",
        "\n",
        "  gen_results = evaluate_model(model, gen_loader, \"Generalization Set\")\n",
        "  gen_results.update({\"model\": MODEL_NAME, \"set\": \"Generalization\"})\n",
        "\n",
        "  all_results.extend([test_results, gen_results])"
      ],
      "metadata": {
        "id": "hrlOyLzk27x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM With Attention**"
      ],
      "metadata": {
        "id": "W9xr966j3SnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=512, output_dim=1000, num_layers=2):\n",
        "        super(LSTMWithAttention, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Attention layer\n",
        "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.context = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attn_scores = torch.tanh(self.attn(lstm_out))  # Compute attention scores\n",
        "        attn_weights = torch.softmax(self.context(attn_scores), dim=1)  # Softmax over time steps\n",
        "        context_vector = (attn_weights * lstm_out).sum(dim=1)  # Weighted sum\n",
        "\n",
        "        output = self.fc(context_vector)  # Final prediction\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "YIdWij9K3VEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"LSTMWithAttention\"\n",
        "DEBUG = True\n",
        "\n",
        "print(f\"\\n---- Evaluating {MODEL_NAME} ----\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(device)\n",
        "\n",
        "# Create dataset with current tokenizer\n",
        "train_dataset = COGSDataset(train_path, tokenizer)\n",
        "test_dataset = COGSDataset(test_path, tokenizer)\n",
        "gen_dataset = COGSDataset(gen_path, tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train the Model\n",
        "train_model(model, train_loader, optimizer)\n",
        "\n",
        "# Check trained model\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.grad is not None}\")\n",
        "\n",
        "# Save model\n",
        "output_dir = f\"models/{MODEL_NAME}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Training complete. Model saved to: {output_dir}\")\n",
        "\n",
        "# Evaluate the Model\n",
        "if DEBUG == True:\n",
        "  debug_results = debug_model(model, test_loader, \"Test Set\")\n",
        "else:\n",
        "  test_results = evaluate_model(model, test_loader, \"Test Set\")\n",
        "  test_results.update({\"model\": MODEL_NAME, \"set\": \"Test\"})\n",
        "\n",
        "  gen_results = evaluate_model(model, gen_loader, \"Generalization Set\")\n",
        "  gen_results.update({\"model\": MODEL_NAME, \"set\": \"Generalization\"})\n",
        "\n",
        "  all_results.extend([test_results, gen_results])"
      ],
      "metadata": {
        "id": "OwdfVPb43gDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(all_results)\n",
        "# df_results.to_csv(\"model_evaluation_results.csv\", index=False)\n",
        "# print(\"📊 All evaluation results saved to: model_evaluation_results.csv\")\n",
        "df_results\n",
        "print(df_results.to_markdown())"
      ],
      "metadata": {
        "id": "rwsLtKyYvu7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-metric columns for plotting\n",
        "metrics = ['exact_match', 'precision', 'recall', 'f1', 'bleu']\n",
        "\n",
        "# Plot each metric\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(data=df_results, x='model', y=metric, hue='set')\n",
        "    plt.title(f'Model Comparison: {metric.capitalize()}')\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "    plt.legend(title=\"Dataset\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "IvNU9ERdu8Y3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}