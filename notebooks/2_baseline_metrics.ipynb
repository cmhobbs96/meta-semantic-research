{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW8Xcv9jcgfj"
      },
      "source": [
        "# 2. Baseline Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cmhobbs96/meta-semantic-research.git"
      ],
      "metadata": {
        "id": "zpBzlXm2ehWY",
        "outputId": "b4ea5a26-5eab-440c-94f6-9a55a9a9be72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'meta-semantic-research' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pandas\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast\n",
        "from torch.cuda.amp import GradScaler\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  scaler = GradScaler()\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  scaler = None"
      ],
      "metadata": {
        "id": "2eE2JOkwzVtS",
        "outputId": "f1ec0fbe-4ad5-40e0-833c-31f79f301e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-58be82d21f76>:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "MODEL = \"t5-small\"\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-5\n",
        "MAX_LENGTH = 512\n",
        "ACCUMULATION_STEPS = 2"
      ],
      "metadata": {
        "id": "6HxEL2XkjJsQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "dataset_dir = \"/content/meta-semantic-research/data/COGS\"\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(os.path.join(dataset_dir, \"train.tsv\"), sep=\"\\t\", header=None)\n",
        "test_df = pd.read_csv(os.path.join(dataset_dir, \"test.tsv\"), sep=\"\\t\", header=None)\n",
        "gen_df = pd.read_csv(os.path.join(dataset_dir, \"gen.tsv\"), sep=\"\\t\", header=None)\n",
        "\n",
        "# Display dataset sample\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "_cuLpliU1D7V",
        "outputId": "966fff71-dca3-403d-8fcd-2b28b34bb733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             0  \\\n",
              "0                 A rose was helped by a dog .   \n",
              "1                    The sailor dusted a boy .   \n",
              "2                      Emma rolled a teacher .   \n",
              "3                     Evelyn rolled the girl .   \n",
              "4  A cake was forwarded to Levi by Charlotte .   \n",
              "\n",
              "                                                   1                2  \n",
              "0  rose ( x _ 1 ) AND help . theme ( x _ 3 , x _ ...  in_distribution  \n",
              "1  * sailor ( x _ 1 ) ; dust . agent ( x _ 2 , x ...  in_distribution  \n",
              "2  roll . agent ( x _ 1 , Emma ) AND roll . theme...  in_distribution  \n",
              "3  * girl ( x _ 3 ) ; roll . agent ( x _ 1 , Evel...  in_distribution  \n",
              "4  cake ( x _ 1 ) AND forward . theme ( x _ 3 , x...  in_distribution  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e77629ff-3979-4ae5-8b63-7b5c3f6691e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A rose was helped by a dog .</td>\n",
              "      <td>rose ( x _ 1 ) AND help . theme ( x _ 3 , x _ ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sailor dusted a boy .</td>\n",
              "      <td>* sailor ( x _ 1 ) ; dust . agent ( x _ 2 , x ...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emma rolled a teacher .</td>\n",
              "      <td>roll . agent ( x _ 1 , Emma ) AND roll . theme...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Evelyn rolled the girl .</td>\n",
              "      <td>* girl ( x _ 3 ) ; roll . agent ( x _ 1 , Evel...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cake was forwarded to Levi by Charlotte .</td>\n",
              "      <td>cake ( x _ 1 ) AND forward . theme ( x _ 3 , x...</td>\n",
              "      <td>in_distribution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e77629ff-3979-4ae5-8b63-7b5c3f6691e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e77629ff-3979-4ae5-8b63-7b5c3f6691e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e77629ff-3979-4ae5-8b63-7b5c3f6691e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-117260e3-38e4-47bf-9803-ef2d49126017\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-117260e3-38e4-47bf-9803-ef2d49126017')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-117260e3-38e4-47bf-9803-ef2d49126017 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 24155,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24155,\n        \"samples\": [\n          \"A cake was given to a patient .\",\n          \"Isabella ran .\",\n          \"The donkey rolled a cake .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24155,\n        \"samples\": [\n          \"cake ( x _ 1 ) AND give . theme ( x _ 3 , x _ 1 ) AND give . recipient ( x _ 3 , x _ 6 ) AND patient ( x _ 6 )\",\n          \"run . agent ( x _ 1 , Isabella )\",\n          \"* donkey ( x _ 1 ) ; roll . agent ( x _ 2 , x _ 1 ) AND roll . theme ( x _ 2 , x _ 4 ) AND cake ( x _ 4 )\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"exposure_example_transitive_subj\",\n          \"exposure_example_active\",\n          \"in_distribution\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Dataset**"
      ],
      "metadata": {
        "id": "fYmJcbp6gMfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset class for COGS\n",
        "class COGSDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input_text = self.data.iloc[index, 0]\n",
        "    output_text = self.data.iloc[index, 1]\n",
        "\n",
        "    inputs = self.tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "    targets = self.tokenizer(output_text, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"labels\": targets[\"input_ids\"].squeeze()\n",
        "    }"
      ],
      "metadata": {
        "id": "o4R48lvazbCo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a tokenizer (T5 example)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Tokenize example sentence\n",
        "example_sentence = \"The dog chased the cat.\"\n",
        "tokens = tokenizer(example_sentence, return_tensors=\"pt\")\n",
        "\n",
        "print(\"Tokenized Output:\", tokens.input_ids)"
      ],
      "metadata": {
        "id": "bWxUgzHG5ObW",
        "outputId": "d29e7db9-542c-461a-8b9b-d575eb2f54aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Output: tensor([[   37,  1782, 15389,    26,     8,  1712,     5,     1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = COGSDataset(train_df, tokenizer)\n",
        "test_dataset = COGSDataset(test_df, tokenizer)\n",
        "gen_dataset = COGSDataset(gen_df, tokenizer)\n",
        "\n",
        "print(train_dataset.data.head())\n",
        "print(train_dataset.data.columns)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "UZMITNH_gZeT",
        "outputId": "b9b6621d-4fd5-4c38-a852-8a1616b8f49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             0  \\\n",
            "0                 A rose was helped by a dog .   \n",
            "1                    The sailor dusted a boy .   \n",
            "2                      Emma rolled a teacher .   \n",
            "3                     Evelyn rolled the girl .   \n",
            "4  A cake was forwarded to Levi by Charlotte .   \n",
            "\n",
            "                                                   1                2  \n",
            "0  rose ( x _ 1 ) AND help . theme ( x _ 3 , x _ ...  in_distribution  \n",
            "1  * sailor ( x _ 1 ) ; dust . agent ( x _ 2 , x ...  in_distribution  \n",
            "2  roll . agent ( x _ 1 , Emma ) AND roll . theme...  in_distribution  \n",
            "3  * girl ( x _ 3 ) ; roll . agent ( x _ 1 , Evel...  in_distribution  \n",
            "4  cake ( x _ 1 ) AND forward . theme ( x _ 3 , x...  in_distribution  \n",
            "Index([0, 1, 2], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T5 Model\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL).to(device)\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "D5u9bmVKgh5Y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, epochs=NUM_EPOCHS):\n",
        "  model.train()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  accumulation_steps = ACCUMULATION_STEPS\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      with autocast(\"cuda\"):\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss / accumulation_steps\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "\n",
        "      if (i + 1) % accumulation_steps == 0:\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "ZlLUt9xMzf9X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "def evaluate_model(model, test_loader, dataset_name):\n",
        "  model.eval()\n",
        "  exact_match = 0\n",
        "  total = 0\n",
        "  predictions_list = []\n",
        "  references_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      input_ids = batch[\"input_ids\"].to(device)\n",
        "      attention_mask = batch[\"attention_mask\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device)\n",
        "\n",
        "      # Generate predictions\n",
        "      outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=MAX_LENGTH)\n",
        "      predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "      references = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "      predictions_list.extend(predictions)\n",
        "      references_list.extend(references)\n",
        "\n",
        "      # Calculate exact match\n",
        "      exact_match += sum([1 for pred, ref in zip(predictions, references) if pred == ref])\n",
        "      total += len(predictions)\n",
        "\n",
        "  # Print 5 sample predictions for debugging\n",
        "  print(\"\\n**Sample Predictions vs. References:**\")\n",
        "  for i in range(min(5, len(predictions_list))):\n",
        "      print(f\"Prediction {i+1}: {predictions_list[i]}\")\n",
        "      print(f\"Reference {i+1}: {references_list[i]}\\n\")\n",
        "\n",
        "  exact_match_score = exact_match / total\n",
        "  print(f\"{dataset_name} Exact Match Score: {exact_match_score:.4f}\")\n",
        "  return exact_match_score\n"
      ],
      "metadata": {
        "id": "VfE-C_O2zhxY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = train_model(model, train_loader, optimizer)"
      ],
      "metadata": {
        "id": "hnpiCgq_l8ZV",
        "outputId": "43b4967f-0799-485a-fec7-5bb13a149516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5885323402601362\n",
            "Epoch 2/5, Loss: 0.10217945859921689\n",
            "Epoch 3/5, Loss: 0.05602065651424673\n",
            "Epoch 4/5, Loss: 0.03968695862255744\n",
            "Epoch 5/5, Loss: 0.030164082656731667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = evaluate_model(model, test_loader, \"Test\")"
      ],
      "metadata": {
        "id": "e8fjz9pDmBOj",
        "outputId": "20b745d7-93f9-4d17-a8ee-f1f2121bf1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Sample Predictions vs. References:**\n",
            "Prediction 1: \n",
            "Reference 1: * cake ( x _ 4 ) ; like. agent ( x _ 1, Mila ) AND like. ccomp ( x _ 1, x _ 6 ) AND offer. theme ( x _ 6, x _ 4 ) AND offer. recipient ( x _ 6, Emma )\n",
            "\n",
            "Prediction 2: \n",
            "Reference 2: * cake ( x _ 5 ) ; coach ( x _ 1 ) AND support. agent ( x _ 2, x _ 1 ) AND support. ccomp ( x _ 2, x _ 7 ) AND snap. theme ( x _ 7, x _ 5 )\n",
            "\n",
            "Prediction 3: \n",
            "Reference 3: * moose ( x _ 1 ) ; want. agent ( x _ 2, x _ 1 ) AND want. xcomp ( x _ 2, x _ 4 ) AND read. agent ( x _ 4, x _ 1 )\n",
            "\n",
            "Prediction 4: \n",
            "Reference 4: * cat ( x _ 6 ) ; box ( x _ 1 ) AND give. theme ( x _ 3, x _ 1 ) AND give. recipient ( x _ 3, x _ 6 ) AND give. agent ( x _ 3, Aiden )\n",
            "\n",
            "Prediction 5: \n",
            "Reference 5: * boy ( x _ 3 ) ; clean. agent ( x _ 1, Emma ) AND clean. theme ( x _ 1, x _ 3 )\n",
            "\n",
            "Test Exact Match Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_results = evaluate_model(model, gen_loader, \"Gen\")"
      ],
      "metadata": {
        "id": "6q2i0mGhmCMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}